# üì± SignLensAI ‚Äî Reconnaissance de la langue des signes (ASL)

Projet √©tudiant (introduction au Machine Learning / Deep Learning).  
Application mobile **Expo React Native** permettant de reconna√Ætre les signes de l‚Äôalphabet am√©ricain (ASL) √† partir de la cam√©ra du t√©l√©phone.

---

## üöÄ Fonctionnalit√©s

- **Mode Photo** : importer une image ou prendre une photo pour obtenir la pr√©diction (Top-3).
- **Mode Live** : lecture continue de la cam√©ra ‚Üí affichage en temps r√©el des lettres reconnues, avec lissage anti-bruit.
- **Historique** (optionnel) : garder une trace des analyses pr√©c√©dentes.
- **Lecture vocale** : prononce la lettre reconnue (via `expo-speech`).
- **Interface moderne** : bas√©e sur la maquette *SignLens* (dark theme, accent color, logo).

---

## üèóÔ∏è Architecture

- **Frontend mobile** : Expo React Native
  - Navigation : `@react-navigation/native`
  - Cam√©ra : `expo-camera`
  - Reconnaissance : mock `useModel()` ‚Üí remplac√© ensuite par **API Flask**
  - UI : composants React Native custom

- **Backend (en cours d‚Äôint√©gration)** : API Flask
  - Expose `/predict_image` et `/predict_landmarks`
  - Charge le mod√®le **mediapipe_vector_model.h5**
  - Retourne les pr√©dictions (Top-3 + Top-1)


---

## ‚öôÔ∏è Installation & Lancement

### Pr√©requis
- Node.js + npm
- Expo CLI (`npx expo`)
- Expo Go install√© sur smartphone

### √âtapes

```bash
# 1. Cloner le repo
git clone https://github.com/Cloxylol/deepLearnigSignLanguage.git
cd signlensai

# 2. Installer les d√©pendances
npm install

# 3. Lancer Expo
npx expo start

```

Scanner le QR code avec Expo Go sur ton t√©l√©phone.



##  üë• Auteurs

+ Clo√© Petetin ‚Äî frontend mobile (Expo)

+ R√©my Legras ‚Äî backend Flask (API / mod√®le)


